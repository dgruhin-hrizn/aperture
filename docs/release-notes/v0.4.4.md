# Aperture v0.4.4 Release Notes

Hey everyone! ğŸ‘‹

This release brings a major architectural upgrade to Aperture's AI infrastructure with **multi-provider LLM support**, plus important bug fixes and mobile UI improvements.

---

## ğŸ¤– Multi-Provider AI System (Vercel AI SDK v5)

Aperture now supports multiple AI providers beyond OpenAI! Choose the best provider for each function based on cost, quality, or privacy needs.

### Supported Providers

**Cloud Providers:**
- **OpenAI** â€” GPT-4o, GPT-4o Mini, GPT-4.1, text-embedding-3-large/small
- **Anthropic** â€” Claude Sonnet 4.5, Claude Haiku 3.5
- **Google** â€” Gemini 2.0 Flash, Gemini 1.5 Pro
- **Groq** â€” Fast inference with Llama, Mixtral, and more
- **DeepSeek** â€” DeepSeek-V3, DeepSeek-R1 (reasoning model)

**Self-Hosted Options:**
- **Ollama** â€” Run models locally (Llama 3.2, Mistral, Qwen, Nomic embeddings)
- **LM Studio** â€” Local model hosting
- **OpenAI-Compatible** â€” Any OpenAI-compatible endpoint

### Per-Function Provider Selection

Choose different providers for different tasks:

- **Embeddings** â€” Use OpenAI embeddings for quality, or Ollama's Nomic models for free self-hosted
- **Chat Assistant (Encore)** â€” Use Claude for better conversations, GPT-4o for tool use, or Ollama for privacy
- **Text Generation** â€” Use GPT-4o Mini for cost efficiency, or DeepSeek for advanced reasoning

Navigate to **Admin â†’ Settings â†’ AI / LLM Setup** to configure.

### Smart Capabilities Detection

Aperture now validates model capabilities and warns you if:
- A model lacks tool calling support (required for Encore assistant)
- A model can't generate embeddings
- A model doesn't support structured output

### Dynamic Pricing & Cost Estimation

- **Real-time pricing** from Helicone API (refreshes weekly)
- **Updated cost estimator** supports all providers
- **Accurate calculations** for embeddings, chat, and text generation
- Shows both cloud and self-hosted options

---

## ğŸ“ Improved Setup Wizard

### AI Configuration Step

The setup wizard now uses the same multi-provider AI configuration:

- **Card-based UI** for each AI function (Embeddings, Chat, Text Generation)
- **All functions required** â€” ensures complete AI functionality from the start
- **Provider auto-detection** â€” shows available providers during setup
- **Connection testing** â€” validates API keys before proceeding

### Setup Wizard Enhancements

- **Exit button** for admins re-running the wizard (returns to Admin Settings)
- **File Locations auto-detection** now more reliable
- **Better error handling** with detailed messages
- **Finish button navigation** properly returns to login or admin settings

---

## ğŸ—„ï¸ Multi-Dimension Embedding Tables

Breaking change for advanced users:

- Separate embedding tables per dimension (256, 384, 512, 768, 1024, 1536, 3072)
- Enables switching between embedding models without conflicts
- Automatic migration of existing embeddings to dimension-specific tables
- Old tables renamed to `*_legacy` for rollback safety

**Why this matters:** You can now switch from text-embedding-3-small (1536d) to text-embedding-3-large (3072d) without re-running embeddings for your entire library.

---

## ğŸ› Bug Fixes

### AI & Assistant Fixes

- **Embedding model format** â€” Fixed assistant search using wrong model ID format (now uses `provider:model`)
- **Dynamic table names** â€” Assistant tools now use correct embedding table based on configured dimensions
- **Setup form population** â€” AI setup wizard now loads existing configuration instead of defaulting to empty
- **Ollama compatibility** â€” Updated to latest ollama-ai-provider for AI SDK v5 compatibility
- **Test connection** â€” Now falls back to saved API keys if not provided in test request

### Setup Wizard Fixes

- **Finish button** â€” Now properly navigates to login (first-run) or admin settings (re-run)
- **Admin access** â€” Admins can now re-enter setup wizard after initial completion
- **User/job endpoints** â€” Fixed 403 errors when admins tried to access setup endpoints
- **Exit button location** â€” Returns admin to their previous location in settings

### UI Fixes

- **Mobile responsiveness** â€” Better layouts for media detail pages and similarity graphs
- **User card spacing** â€” Fixed spacing between labels and toggles on mobile
- **Create Playlist button** â€” Proper sizing and no word wrap
- **Graph info button** â€” New â“˜ button on graph nodes to navigate to detail page without drilling down
- **Legacy embeddings section** â€” Fixed interface mismatch with API response

### CI/CD

- **Docker tags** â€” Removed SHA tagging to prevent GHCR storage bloat (only `dev`, `latest`, and version tags remain)

---

## ğŸ“Š Technical Details

### New Database Migrations

Three new migrations run automatically on upgrade:

- **0075_ai_provider_config.sql** â€” New `ai_config` system setting, migrates existing OpenAI configs
- **0076_fix_ai_config_api_keys.sql** â€” Ensures proper API key migration for existing users
- **0077_update_embedding_model_names.sql** â€” Updates embedding model IDs to new `provider:model` format
- **0078_multi_dimension_embeddings.sql** â€” Creates dimension-specific embedding tables

### New API Endpoints

**AI Configuration:**
- `GET /api/settings/ai/providers` â€” List available AI providers
- `GET /api/settings/ai/models` â€” Get models for a provider and function
- `GET /api/settings/ai/:function` â€” Get current config for embeddings/chat/textGeneration
- `PATCH /api/settings/ai/:function` â€” Update function configuration
- `POST /api/settings/ai/test` â€” Test provider connection with credentials
- `GET /api/settings/ai/credentials/:provider` â€” Get saved credentials for a provider

**Setup Wizard:**
- `GET /api/setup/ai/*` â€” Unauthenticated versions of AI endpoints for first-run setup
- Uses `requireSetupWritable()` pattern (public during first-run, admin-only after)

### New Background Job

- **refresh-ai-pricing** â€” Fetches latest pricing from Helicone API weekly (AI System category)

### New Dependencies

```json
{
  "@ai-sdk/openai": "^1.0.7",
  "@ai-sdk/anthropic": "^1.0.8",
  "@ai-sdk/google": "^1.0.11",
  "@ai-sdk/groq": "^1.0.8",
  "@ai-sdk/deepseek": "^1.0.3",
  "ai-sdk-ollama": "^2.2.0"
}
```

---

## ğŸš€ Upgrade Instructions

### For OpenAI Users

Your existing configuration will migrate automatically:
- OpenAI API key preserved
- Embedding model updated to `openai:text-embedding-3-large` (or small)
- Chat and text generation models set to `openai:gpt-4o-mini`
- No action required!

### For New Installations

1. Run through the setup wizard
2. Configure AI providers in the new AI Setup step
3. Choose providers for each function (all three required)
4. Test connections before proceeding

### For Advanced Users

1. **Backup your database** before upgrading (automatic backups run daily)
2. Migrations will run automatically
3. Existing embeddings migrate to dimension-specific tables
4. Review your AI configuration in **Admin â†’ Settings â†’ AI / LLM Setup**
5. Consider switching to cost-effective providers (e.g., GPT-4o Mini for text generation)

---

## ğŸ’¡ Use Cases

### Cost Optimization

```
Embeddings:    text-embedding-3-small ($0.02/M tokens)
Chat:          GPT-4o Mini ($0.15/$0.60 per M)
Text Gen:      GPT-4o Mini ($0.15/$0.60 per M)

Estimated monthly cost for 1000 movies: ~$2-5
```

### Self-Hosted Privacy

```
Embeddings:    Ollama (nomic-embed-text)
Chat:          Ollama (llama3.2)
Text Gen:      Ollama (mistral)

Cost: $0 (runs locally)
```

### Balanced Approach

```
Embeddings:    OpenAI text-embedding-3-large (best quality)
Chat:          Claude Sonnet 4.5 (best conversation)
Text Gen:      DeepSeek-V3 (best reasoning, low cost)
```

---

## ğŸ”„ Breaking Changes

### AI Configuration Format

The `ai_config` system setting now uses a structured format:

```json
{
  "embeddings": { "provider": "openai", "model": "text-embedding-3-large", ... },
  "chat": { "provider": "anthropic", "model": "claude-sonnet-4-5", ... },
  "textGeneration": { "provider": "openai", "model": "gpt-4o-mini", ... }
}
```

Old OpenAI-specific settings are migrated automatically.

### Embedding Model IDs

Model IDs now include provider prefix: `openai:text-embedding-3-large` instead of just `text-embedding-3-large`.

Database migration handles this automatically.

---

## ğŸ¯ What's Next?

In future releases, you can expect:
- More AI provider integrations
- Custom model fine-tuning support
- Advanced embedding strategies (hybrid search, reranking)
- Per-user AI provider preferences

---

## ğŸ™ Credits

Big thanks to the AI SDK team at Vercel for the excellent multi-provider abstraction layer, and to the community for testing and feedback on the mobile UI improvements!

---

Enjoy the flexibility of choosing your AI providers! If you run into any issues or have questions, please open an issue on GitHub. ğŸ¿

