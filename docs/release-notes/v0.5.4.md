# Aperture v0.5.4 Release Notes

Hey everyone! üëã

This release adds **Hugging Face** as a new AI provider and introduces **configurable embedding dimensions** for custom models.

---

## ü§ó Hugging Face Provider Support

You can now use **Hugging Face Inference API** as your AI provider! Access thousands of models from Meta, DeepSeek, Qwen, and more.

### How to Use

1. Go to **Admin ‚Üí Settings ‚Üí AI / LLM**
2. Select **Hugging Face** from the provider dropdown
3. Enter your API key from [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)
4. Click **Add Custom Model...** to enter any model name
5. Test the connection and save

### Custom Models Only

Like OpenRouter, Hugging Face uses custom model IDs ‚Äî you enter the exact model path:

- `meta-llama/Llama-3.3-70B-Instruct`
- `deepseek-ai/DeepSeek-V3-0324`
- `Qwen/Qwen3-235B-A22B-Instruct-2507`
- `google/gemma-3-27b-it`
- `moonshotai/Kimi-K2-Instruct`

Find available models at [huggingface.co/models](https://huggingface.co/models) or browse inference models at [huggingface.co/inference/models](https://huggingface.co/inference/models).

---

## üìê Configurable Embedding Dimensions

Custom embedding models now require you to specify the **vector dimension size**. This ensures embeddings are stored correctly and similarity searches work properly.

### Why This Matters

Different embedding models output different dimension sizes. If the dimension doesn't match what the model outputs, embedding generation will fail or produce incorrect results.

### How to Use

When adding a custom embedding model:

1. Select your provider (Ollama, OpenRouter, HuggingFace, or OpenAI-Compatible)
2. Choose **Embeddings** as the function
3. Click **Add Custom Model...**
4. Enter the model name
5. **Select the correct dimension** from the dropdown
6. Test and save

### Supported Dimensions

| Dimensions | Example Models |
|------------|----------------|
| **384** | granite-embedding-30m-english, all-MiniLM-L6-v2 |
| **768** | nomic-embed-text, snowflake-arctic-embed-m, e5-base-v2 |
| **1024** | mxbai-embed-large, snowflake-arctic-embed-l, voyage-multilingual-2 |
| **1536** | OpenAI text-embedding-3-small, text-embedding-ada-002 |
| **3072** | OpenAI text-embedding-3-large |
| **4096** | nv-embed-v2, larger custom models |

### 4096 Dimension Support

Added support for 4096-dimension embeddings using **binary quantized HNSW indexes** (pgvector's standard indexes have a 4000-dimension limit).

---

## üöÄ Update Instructions

### For Docker Users

```bash
# Pull the latest image
docker compose pull

# Restart with new version
docker compose up -d
```

### Database Migrations

This update includes two migrations that run automatically on startup:

- `0091_embedding_dimensions_4096.sql` ‚Äî Adds embedding dimension support and 4096-dim tables
- `0092_huggingface_provider.sql` ‚Äî Adds HuggingFace to provider constraint

### Post-Update Steps

1. **Clear browser cache** ‚Äî Or hard refresh (Cmd+Shift+R / Ctrl+Shift+R)
2. **Re-add custom embedding models** ‚Äî Existing custom embedding models may need to be re-added with the correct dimension selected

---

## üìã Full Changelog

**Hugging Face Integration:**
- `feat: add @ai-sdk/huggingface package`
- `feat: add HuggingFace to provider registry`
- `feat: add HuggingFace logo`
- `feat: update custom model support for HuggingFace`
- `feat: add database migration for HuggingFace provider`

**Embedding Dimensions:**
- `feat: add embedding_dimensions column to custom_ai_models table`
- `feat: create 4096-dimension embedding tables with binary quantized indexes`
- `feat: add dimension dropdown to custom model dialog (embeddings only)`
- `feat: add detailed warning about matching dimensions to model output`
- `feat: validate embedding dimensions on API endpoints`

---

Enjoy Hugging Face support and better embedding control! üöÄ
